\begin{thebibliography}{}

\bibitem[\protect\astroncite{Andrychowicz et~al.}{2018}]{OpenAISim2real}
Andrychowicz, M., Baker, B., et~al. (2018).
\newblock Learning dexterous in-hand manipulation.

\bibitem[\protect\astroncite{Beattie et~al.}{2016}]{DeepmindLab}
Beattie, C., Leibo, J.~Z., et~al. (2016).
\newblock Deepmind lab.

\bibitem[\protect\astroncite{{Bellemare} et~al.}{2013}]{BellemareALE}
{Bellemare}, M.~G., {Naddaf}, Y., et~al. (2013).
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock {\em Journal of Artificial Intelligence Research}, 47:253--279.

\bibitem[\protect\astroncite{Bengio et~al.}{2009}]{CurriculumLearningBengio}
Bengio, Y., Louradour, J., et~al. (2009).
\newblock Curriculum learning.
\newblock In {\em Proceedings of the 26th annual international conference on
  machine learning}, pages 41--48. ACM.

\bibitem[\protect\astroncite{Berseth et~al.}{2018}]{TerrainRLSim}
Berseth, G., Peng, X.~B., et~al. (2018).
\newblock Terrain rl simulator.

\bibitem[\protect\astroncite{Brockman et~al.}{2016}]{Gym}
Brockman, G., Cheung, V., et~al. (2016).
\newblock Openai gym.

\bibitem[\protect\astroncite{Coumans}{2014}]{ErwinCowmansMlcp}
Coumans, E. (2014).
\newblock Exploring mlcp solvers and featherstone.

\bibitem[\protect\astroncite{Coumans}{2015}]{Bullet}
Coumans, E. (2015).
\newblock Bullet physics simulation.
\newblock In {\em ACM SIGGRAPH 2015 Courses}, SIGGRAPH '15, New York, NY, USA.
  ACM.

\bibitem[\protect\astroncite{Coumans and Bai}{2019}]{PyBullet}
Coumans, E. and Bai, Y. (2016--2019).
\newblock Pybullet, a python module for physics simulation for games, robotics
  and machine learning.

\bibitem[\protect\astroncite{Duan et~al.}{2016}]{Rllab}
Duan, Y., Chen, X., et~al. (2016).
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock ICML.

\bibitem[\protect\astroncite{Fan et~al.}{2018}]{Surreal}
Fan, L., Zhu, Y., et~al. (2018).
\newblock Surreal: Open-source reinforcement learning framework and robot
  manipulation benchmark.
\newblock In {\em Conference on Robot Learning}.

\bibitem[\protect\astroncite{Featherstone}{1987}]{Featherstone}
Featherstone, R. (1987).
\newblock {\em Robot Dynamics Algorithms}.
\newblock Springer.

\bibitem[\protect\astroncite{Heess et~al.}{2017}]{DeepmindEmergenceLocomotion}
Heess, N., TB, D., et~al. (2017).
\newblock Emergence of locomotion behaviours in rich environments.

\bibitem[\protect\astroncite{Holden et~al.}{2017}]{Pfnn}
Holden, D., Komura, T., et~al. (2017).
\newblock Phased-functioned neural networks for character control.
\newblock volume~36. ACM Transactions on Graphics.

\bibitem[\protect\astroncite{Juliani et~al.}{2018}]{UnityMLAgents}
Juliani, A., Berges, V.-P., et~al. (2018).
\newblock Unity: A general platform for intelligent agents.

\bibitem[\protect\astroncite{Kalashnikov et~al.}{2018}]{ScalableDeepRL}
Kalashnikov, D., Irpan, A., et~al. (2018).
\newblock Qt-opt: Scalable deep reinforcement learning for vision-based robotic
  manipulation.
\newblock In {\em Conference of Robot Learning}.

\bibitem[\protect\astroncite{Legg and Hutter}{2007}]{UniversalIntelligence}
Legg, S. and Hutter, M. (2007).
\newblock Universal intelligence: A definition of machine intelligence.
\newblock {\em Minds and Machines}.

\bibitem[\protect\astroncite{Levine et~al.}{2016}]{EndToEndVisuoMotorPolicies}
Levine, S., Finn, C., et~al. (2016).
\newblock End-to-end training of deep visuomotor policies.

\bibitem[\protect\astroncite{Liang et~al.}{2018}]{GpuSim}
Liang, J., Makoviychuk, V., et~al. (2018).
\newblock Gpu-accelerated robotics simulation for distributed reinforcement
  learning.
\newblock In {\em Conference on Robot Learning}.

\bibitem[\protect\astroncite{Mnih et~al.}{2015}]{DQNAtari}
Mnih, V., Kavukcuoglu, K., et~al. (2015).
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518:529--533.

\bibitem[\protect\astroncite{NVIDIA}{a}]{FleX}
NVIDIA.
\newblock Flex. https://developer.nvidia.com/flex.

\bibitem[\protect\astroncite{NVIDIA}{b}]{PhysX}
NVIDIA.
\newblock Physx: A multi-platform physics solution.

\bibitem[\protect\astroncite{OpenAI}{2017}]{Roboschool}
OpenAI (2017).
\newblock Roboschool.

\bibitem[\protect\astroncite{Peng et~al.}{2018}]{DeepMimic}
Peng, X.~B., Abbeel, P., et~al. (2018).
\newblock Deepmimic: Example-guided deep reinforcement learning of
  physics-based character skills.
\newblock {\em ACM Trans. Graph.}, 37(4):143:1--143:14.

\bibitem[\protect\astroncite{Peng et~al.}{2016}]{DeepTerrainRL}
Peng, X.~B., Berseth, G., et~al. (2016).
\newblock Terrain-adaptive locomotion skills using deep reinforcement learning.
\newblock {\em ACM Transactions on Graphics (Proc. SIGGRAPH 2016)}, 35(4).

\bibitem[\protect\astroncite{Peng et~al.}{2017}]{DeepLoco}
Peng, X.~B., Berseth, G., et~al. (2017).
\newblock Deeploco: Dynamic locomotion skills using hierarchical deep
  reinforcement learning.
\newblock {\em ACM Trans. Graph.}, 36(4):41:1--41:13.

\bibitem[\protect\astroncite{Peng and van~de Panne}{2017}]{ActuationChoice}
Peng, X.~B. and van~de Panne, M. (2017).
\newblock Learning locomotion skills using deeprl: Does the choice of action
  space matter?
\newblock In {\em Proceedings of the ACM SIGGRAPH / Eurographics Symposium on
  Computer Animation}, SCA '17, pages 12:1--12:13, New York, NY, USA. ACM.

\bibitem[\protect\astroncite{Schulman et~al.}{2015}]{TRPO}
Schulman, J., Levine, S., et~al. (2015).
\newblock Trust region policy optimization.
\newblock ICML.

\bibitem[\protect\astroncite{Schulman et~al.}{2017}]{PPO}
Schulman, J., Wolski, F., et~al. (2017).
\newblock Proximal policy optimization algorithms.

\bibitem[\protect\astroncite{Silver et~al.}{2016}]{AlphaGo}
Silver, D., Huang, A., et~al. (2016).
\newblock Mastering the game of go with deep neural network and tree search.
\newblock {\em Nature}, 529:484--489.

\bibitem[\protect\astroncite{Sutton et~al.}{2000}]{PGSutton}
Sutton, R., McAllester, D., et~al. (2000).
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock {\em NIPS}.

\bibitem[\protect\astroncite{Tan et~al.}{2018}]{GoogleBrainSim2Real}
Tan, J., amd Erwin~Coumans, T.~Z., et~al. (2018).
\newblock Sim-to-real: Learning agile locomotion for quadruped robots.

\bibitem[\protect\astroncite{Tassa et~al.}{2018}]{Controlsuite}
Tassa, Y., Doron, Y., et~al. (2018).
\newblock Deepmind control suite.

\bibitem[\protect\astroncite{Todorov et~al.}{2012}]{MuJoCo}
Todorov, E., Erez, T., et~al. (2012).
\newblock Mujoco: A physics engine for model-based control.

\bibitem[\protect\astroncite{Unity}{}]{Unity}
Unity.
\newblock Unity3d. https://unity3d.com/.

\bibitem[\protect\astroncite{Unreal}{}]{Unreal}
Unreal.
\newblock Unreal engine. https://www.unrealengine.com/.

\end{thebibliography}
